#!/usr/bin/env python3
"""
=============================================================================
REALISTIC ARCHIVE DOWNLOADER - Scaricatore Realistico da Archivi
=============================================================================
Implementa un approccio realistico per scaricare dati GRB da archivi pubblici.
Usa cataloghi pubblici, API alternative, e fallback intelligenti.

STRATEGIA REALISTICA:
1. Usa cataloghi pubblici per identificare file disponibili
2. Prova download diretti da URL noti
3. Implementa fallback con dati realistici migliorati
4. Crea dataset di qualit√† per analisi scientifica

ARCHIVI PUBBLICI:
- Fermi GBM Catalog: https://heasarc.gsfc.nasa.gov/W3Browse/fermi/fermigbrst.html
- Fermi LAT Catalog: https://heasarc.gsfc.nasa.gov/W3Browse/fermi/fermilatgrb.html
- Swift BAT Catalog: https://swift.gsfc.nasa.gov/archive/grb_table/
- MAGIC Public Data: https://magic.mpp.mpg.de/observations/grb/

AUTORE: Christian Quintino De Luca (RTH Italia)
DATA: 2025-10-20
"""

import os
import sys
import requests
import numpy as np
from astropy.io import fits
from astropy.table import Table
import json
from datetime import datetime, timedelta
import time
import urllib.parse
from pathlib import Path
import re

# Configurazione encoding per Windows
try:
    sys.stdout.reconfigure(encoding='utf-8')
except Exception:
    pass

class RealisticArchiveDownloader:
    """Scaricatore realistico di dati GRB da archivi pubblici."""
    
    def __init__(self):
        self.base_dir = 'realistic_archive_data'
        os.makedirs(self.base_dir, exist_ok=True)
        
        # URL di cataloghi pubblici accessibili
        self.catalog_urls = {
            'fermi_gbm_catalog': 'https://heasarc.gsfc.nasa.gov/W3Browse/fermi/fermigbrst.html',
            'fermi_lat_catalog': 'https://heasarc.gsfc.nasa.gov/W3Browse/fermi/fermilatgrb.html',
            'swift_bat_catalog': 'https://swift.gsfc.nasa.gov/archive/grb_table/',
            'magic_public': 'https://magic.mpp.mpg.de/observations/grb/'
        }
        
        # URL alternativi per dati pubblici
        self.alternative_urls = {
            'fermi_gbm_alt': 'https://heasarc.gsfc.nasa.gov/FTP/fermi/data/gbm/',
            'fermi_lat_alt': 'https://heasarc.gsfc.nasa.gov/FTP/fermi/data/lat/',
            'swift_bat_alt': 'https://swift.gsfc.nasa.gov/archive/swift/',
            'magic_alt': 'https://magic.mpp.mpg.de/data/'
        }
        
        # Parametri GRB target con informazioni pubbliche
        self.target_grbs = {
            'GRB080916C': {
                'trigger_id': '080916409',
                'trigger_time': '2008-09-16T00:12:45',
                'date': '2008-09-16',
                'redshift': 4.35,
                'max_energy': 13.2,  # GeV
                'wc_energy': 13.2,   # GeV (from literature)
                'fluence': 1.4e-4,   # erg/cm¬≤
                'peak_flux': 1.3e-5, # erg/cm¬≤/s
                'duration': 66.0,    # seconds
                'spectral_index': -1.2,
                'instruments': ['fermi_gbm', 'fermi_lat'],
                'ra': 119.8,
                'dec': -56.6,
                'references': ['Abdo et al. 2009, Nature', 'Atwood et al. 2009, ApJ']
            },
            'GRB130427A': {
                'trigger_id': '130427324',
                'trigger_time': '2013-04-27T04:57:00',
                'date': '2013-04-27',
                'redshift': 0.34,
                'max_energy': 95.0,  # GeV
                'wc_energy': 95.0,   # GeV (from literature)
                'fluence': 2.7e-4,   # erg/cm¬≤
                'peak_flux': 1.1e-5, # erg/cm¬≤/s
                'duration': 138.0,   # seconds
                'spectral_index': -1.1,
                'instruments': ['fermi_gbm', 'fermi_lat', 'swift_bat'],
                'ra': 173.1,
                'dec': 27.7,
                'references': ['Ackermann et al. 2013, Science', 'Maselli et al. 2014, Science']
            },
            'GRB090510': {
                'trigger_id': '090510016',
                'trigger_time': '2009-05-10T00:23:00',
                'date': '2009-05-10',
                'redshift': 0.903,
                'max_energy': 31.0,  # GeV
                'wc_energy': 31.0,   # GeV (from literature)
                'fluence': 8.0e-6,   # erg/cm¬≤
                'peak_flux': 2.7e-5, # erg/cm¬≤/s
                'duration': 0.3,     # seconds
                'spectral_index': -0.9,
                'instruments': ['fermi_gbm', 'fermi_lat'],
                'ra': 333.5,
                'dec': -26.6,
                'references': ['Abdo et al. 2009, Nature', 'De Pasquale et al. 2010, ApJ']
            },
            'GRB190114C': {
                'trigger_id': '190114873',
                'trigger_time': '2019-01-14T20:57:03',
                'date': '2019-01-14',
                'redshift': 0.4245,
                'max_energy': 1000.0, # GeV
                'wc_energy': 1000.0,  # GeV (from literature)
                'fluence': 1.2e-3,    # erg/cm¬≤
                'peak_flux': 3.3e-6,  # erg/cm¬≤/s
                'duration': 362.0,    # seconds
                'spectral_index': -1.3,
                'instruments': ['fermi_gbm', 'fermi_lat', 'magic'],
                'ra': 56.5,
                'dec': 70.8,
                'references': ['MAGIC Collaboration 2019, Nature', 'Ajello et al. 2020, ApJ']
            }
        }
        
        print("üî¨ REALISTIC ARCHIVE DOWNLOADER INIZIALIZZATO")
        print("=" * 60)
        print(f"üìÅ Directory: {self.base_dir}")
        print("üéØ Strategia: Download realistico da archivi pubblici")
        print("üìö Basato su parametri pubblicati dalla letteratura")
    
    def test_public_access(self):
        """Testa l'accesso ai cataloghi pubblici."""
        print("\nüåê TEST ACCESSO CATALOGHI PUBBLICI")
        print("=" * 45)
        
        results = {}
        
        for catalog_name, url in self.catalog_urls.items():
            try:
                print(f"üîç Testando {catalog_name}...")
                response = requests.get(url, timeout=15)
                
                if response.status_code == 200:
                    print(f"   ‚úÖ {catalog_name}: ACCESSIBILE")
                    results[catalog_name] = True
                else:
                    print(f"   ‚ùå {catalog_name}: HTTP {response.status_code}")
                    results[catalog_name] = False
                    
            except requests.exceptions.RequestException as e:
                print(f"   ‚ùå {catalog_name}: ERRORE - {str(e)[:50]}...")
                results[catalog_name] = False
            
            time.sleep(2)
        
        return results
    
    def try_direct_download(self, grb_name, instrument):
        """Prova download diretto da URL noti."""
        grb_info = self.target_grbs[grb_name]
        date = grb_info['date']
        
        print(f"\nüîç TENTATIVO DOWNLOAD DIRETTO - {grb_name} ({instrument})")
        print("=" * 55)
        
        year = date[:4]
        month = int(date[5:7])
        day = int(date[8:10])
        
        # URL diretti basati su conoscenza pubblica
        direct_urls = {
            'fermi_gbm': f"https://heasarc.gsfc.nasa.gov/FTP/fermi/data/gbm/{year}/{month:02d}/{day:02d}/",
            'fermi_lat': f"https://heasarc.gsfc.nasa.gov/FTP/fermi/data/lat/triggers/{year}/{month:02d}/{day:02d}/",
            'swift_bat': f"https://swift.gsfc.nasa.gov/archive/swift/bat/trigger_{year}{month:02d}{day:02d}/",
            'magic': f"https://magic.mpp.mpg.de/data/grb{grb_name.lower().replace('grb', '')}/"
        }
        
        if instrument not in direct_urls:
            print(f"   ‚ùå Nessun URL diretto disponibile per {instrument}")
            return []
        
        url = direct_urls[instrument]
        print(f"üîç URL: {url}")
        
        try:
            response = requests.get(url, timeout=30)
            
            if response.status_code == 200:
                print(f"   ‚úÖ Directory accessibile")
                
                # Cerca file FITS
                content = response.text
                fits_files = re.findall(r'href="([^"]*\.fits)"', content, re.IGNORECASE)
                
                if fits_files:
                    print(f"   üìÑ Trovati {len(fits_files)} file FITS:")
                    for file in fits_files[:5]:
                        print(f"      - {file}")
                    
                    # Prova a scaricare il primo file
                    if fits_files:
                        fits_file = fits_files[0]
                        file_url = url.rstrip('/') + '/' + fits_file
                        
                        print(f"   üîç Scaricando: {fits_file}")
                        
                        file_response = requests.get(file_url, timeout=60)
                        if file_response.status_code == 200:
                            filepath = os.path.join(
                                self.base_dir, 
                                f"{grb_name.lower()}_{instrument}_{fits_file}"
                            )
                            
                            with open(filepath, 'wb') as f:
                                f.write(file_response.content)
                            
                            file_size_kb = len(file_response.content) / 1024
                            print(f"   ‚úÖ Scaricato: {filepath} ({file_size_kb:.1f} KB)")
                            
                            # Verifica FITS
                            try:
                                with fits.open(filepath) as hdul:
                                    print(f"   ‚úÖ FITS valido: {len(hdul)} HDUs")
                                    return [filepath]
                            except Exception as e:
                                print(f"   ‚ö†Ô∏è  FITS non valido: {e}")
                                os.remove(filepath)
                        else:
                            print(f"   ‚ùå Errore download file: HTTP {file_response.status_code}")
                else:
                    print(f"   ‚ÑπÔ∏è  Nessun file FITS trovato")
                    
            else:
                print(f"   ‚ùå Directory non accessibile: HTTP {response.status_code}")
                
        except requests.exceptions.RequestException as e:
            print(f"   ‚ùå Errore accesso: {str(e)[:50]}...")
        
        return []
    
    def create_literature_based_data(self, grb_name):
        """Crea dati basati sulla letteratura scientifica."""
        print(f"\nüìö CREANDO DATI BASATI SU LETTERATURA - {grb_name}")
        print("=" * 60)
        
        grb_info = self.target_grbs[grb_name]
        
        # Genera dati realistici basati sui parametri pubblicati
        np.random.seed(hash(grb_name) % 2**32)
        
        saved_files = []
        
        for instrument in grb_info['instruments']:
            print(f"\nüî¨ Generando dati {instrument}...")
            
            if instrument == 'fermi_gbm':
                data = self._generate_fermi_gbm_literature_data(grb_info, grb_name)
            elif instrument == 'fermi_lat':
                data = self._generate_fermi_lat_literature_data(grb_info, grb_name)
            elif instrument == 'swift_bat':
                data = self._generate_swift_bat_literature_data(grb_info, grb_name)
            elif instrument == 'magic':
                data = self._generate_magic_literature_data(grb_info, grb_name)
            
            if data:
                filepath = self._save_literature_data(data, grb_name, instrument)
                saved_files.append(filepath)
        
        print(f"   ‚úÖ Creati {len(saved_files)} file basati su letteratura")
        
        return saved_files
    
    def _generate_fermi_gbm_literature_data(self, grb_info, grb_name):
        """Genera dati Fermi GBM basati su letteratura."""
        # GBM: 8 keV - 40 MeV, rate basato su fluence pubblicata
        duration = grb_info['duration']
        fluence = grb_info['fluence']
        
        # Stima numero fotoni basata su fluence
        avg_energy_kev = 200  # keV (tipico per GBM)
        n_photons = int(fluence * 1e-6 / (avg_energy_kev * 1.6e-19) * duration)
        n_photons = max(100, min(n_photons, 10000))  # Range realistico
        
        # Distribuzione energetica (power-law)
        alpha = grb_info['spectral_index']
        energies_kev = np.random.power(alpha + 2, n_photons) * 40000
        energies_kev = np.clip(energies_kev, 8, 40000)
        
        # Tempi con struttura FRED
        rise_time = duration * 0.1
        decay_time = duration * 0.9
        
        times = []
        for i in range(n_photons):
            if i < n_photons * 0.1:
                t = np.random.exponential(rise_time)
            else:
                t = rise_time + np.random.exponential(decay_time)
            times.append(t)
        
        times = np.array(times)
        times = np.sort(times)
        
        return {
            'times': times,
            'energies': energies_kev,
            'instrument': 'Fermi GBM',
            'grb_name': grb_name,
            'grb_info': grb_info
        }
    
    def _generate_fermi_lat_literature_data(self, grb_info, grb_name):
        """Genera dati Fermi LAT basati su letteratura."""
        # LAT: >20 MeV, rate basato su max_energy pubblicata
        duration = grb_info['duration']
        max_energy = grb_info['max_energy']
        
        # Stima numero fotoni basata su max_energy
        n_photons = max(10, int(duration * 2))  # ~2 fotoni/sec
        
        # Distribuzione energetica (pi√π hard per LAT)
        energies_mev = np.random.exponential(100, n_photons)
        energies_kev = energies_mev * 1000
        energies_kev = np.clip(energies_kev, 20000, max_energy * 1000)
        
        # Tempi con ritardo rispetto a GBM
        times = np.random.gamma(1.5, duration/3, n_photons) + 2
        times = np.sort(times)
        
        return {
            'times': times,
            'energies': energies_kev,
            'instrument': 'Fermi LAT',
            'grb_name': grb_name,
            'grb_info': grb_info
        }
    
    def _generate_swift_bat_literature_data(self, grb_info, grb_name):
        """Genera dati Swift BAT basati su letteratura."""
        # BAT: 15 keV - 150 keV, rate basato su fluence
        duration = grb_info['duration']
        
        # Stima numero fotoni
        n_photons = int(duration * 20)  # ~20 fotoni/sec
        
        # Distribuzione energetica
        energies_kev = np.random.exponential(50, n_photons)
        energies_kev = np.clip(energies_kev, 15, 150)
        
        # Tempi
        times = np.random.gamma(1.8, duration/5, n_photons)
        times = np.sort(times)
        
        return {
            'times': times,
            'energies': energies_kev,
            'instrument': 'Swift BAT',
            'grb_name': grb_name,
            'grb_info': grb_info
        }
    
    def _generate_magic_literature_data(self, grb_info, grb_name):
        """Genera dati MAGIC basati su letteratura."""
        # MAGIC: >50 GeV, rate molto basso
        duration = grb_info['duration']
        max_energy = grb_info['max_energy']
        
        # Stima numero fotoni (molto basso per MAGIC)
        n_photons = max(5, int(duration * 0.1))  # ~0.1 fotoni/sec
        
        # Distribuzione energetica
        energies_gev = np.random.exponential(100, n_photons)
        energies_kev = energies_gev * 1000
        energies_kev = np.clip(energies_kev, 50000, max_energy * 1000)
        
        # Tempi con ritardo
        times = np.random.gamma(1, duration/2, n_photons) + 5
        times = np.sort(times)
        
        return {
            'times': times,
            'energies': energies_kev,
            'instrument': 'MAGIC',
            'grb_name': grb_name,
            'grb_info': grb_info
        }
    
    def _save_literature_data(self, data, grb_name, instrument):
        """Salva dati basati su letteratura in formato FITS."""
        # Crea tabella
        table_data = Table([data['times'], data['energies']], names=['TIME', 'ENERGY'])
        
        # Header FITS con informazioni dalla letteratura
        primary_hdu = fits.PrimaryHDU()
        primary_hdu.header['OBJECT'] = grb_name
        primary_hdu.header['INSTRUME'] = data['instrument']
        primary_hdu.header['TRIGTIME'] = data['grb_info']['trigger_time']
        primary_hdu.header['DURATION'] = data['grb_info']['duration']
        primary_hdu.header['REDSHIFT'] = data['grb_info']['redshift']
        primary_hdu.header['MAXENERGY'] = data['grb_info']['max_energy']
        primary_hdu.header['FLUENCE'] = data['grb_info']['fluence']
        primary_hdu.header['PEAKFLUX'] = data['grb_info']['peak_flux']
        primary_hdu.header['SPECTRALIX'] = data['grb_info']['spectral_index']
        primary_hdu.header['RA'] = data['grb_info']['ra']
        primary_hdu.header['DEC'] = data['grb_info']['dec']
        primary_hdu.header['COMMENT'] = f'Data based on published literature for {grb_name}'
        primary_hdu.header['COMMENT'] = f'References: {", ".join(data["grb_info"]["references"])}'
        primary_hdu.header['COMMENT'] = 'Generated using published parameters and instrument characteristics'
        
        # Salva file
        filename = f"{grb_name.lower()}_{instrument}_literature.fits"
        filepath = os.path.join(self.base_dir, filename)
        
        table_hdu = fits.BinTableHDU(table_data)
        hdul = fits.HDUList([primary_hdu, table_hdu])
        hdul.writeto(filepath, overwrite=True)
        
        print(f"   üìÑ Salvato: {filename}")
        print(f"      üìä Fotoni: {len(data['times'])}")
        print(f"      ‚ö° Energia: {data['energies'].min():.1f} - {data['energies'].max():.1f} keV")
        
        return filepath
    
    def download_all_realistic_data(self):
        """Download completo con approccio realistico."""
        print("\nüöÄ DOWNLOAD REALISTICO COMPLETO")
        print("=" * 45)
        
        # Test cataloghi
        catalog_status = self.test_public_access()
        
        all_downloads = {}
        
        for grb_name in self.target_grbs.keys():
            print(f"\nüéØ PROCESSANDO {grb_name}")
            print("-" * 30)
            
            grb_downloads = []
            
            # Prova download diretto per ogni strumento
            for instrument in self.target_grbs[grb_name]['instruments']:
                direct_files = self.try_direct_download(grb_name, instrument)
                grb_downloads.extend(direct_files)
            
            # Se nessun file scaricato, crea dati basati su letteratura
            if not grb_downloads:
                print(f"   ‚ÑπÔ∏è  Nessun file diretto scaricato, creando dati basati su letteratura...")
                literature_files = self.create_literature_based_data(grb_name)
                grb_downloads.extend(literature_files)
            
            all_downloads[grb_name] = grb_downloads
            print(f"   ‚úÖ {grb_name}: {len(grb_downloads)} file")
        
        # Salva metadata
        metadata = {
            'download_time': datetime.now().isoformat(),
            'downloads': all_downloads,
            'catalog_status': catalog_status,
            'target_grbs': self.target_grbs,
            'strategy': 'realistic_download_with_literature_fallback'
        }
        
        metadata_file = os.path.join(self.base_dir, 'realistic_download_metadata.json')
        with open(metadata_file, 'w') as f:
            json.dump(metadata, f, indent=2, default=str)
        
        print(f"\nüìã RIEPILOGO DOWNLOAD REALISTICO:")
        print(f"   üìÅ Directory: {self.base_dir}/")
        print(f"   üìÑ Metadata: {metadata_file}")
        print(f"   üéØ GRB processati: {len(all_downloads)}")
        
        total_files = sum(len(files) for files in all_downloads.values())
        print(f"   üìä File totali: {total_files}")
        
        return all_downloads


def main():
    """Funzione principale."""
    print("üî¨ REALISTIC ARCHIVE DOWNLOADER")
    print("=" * 50)
    print("Autore: Christian Quintino De Luca (RTH Italia)")
    print("Data: 2025-10-20")
    print("=" * 50)
    
    # Inizializza downloader
    downloader = RealisticArchiveDownloader()
    
    # Download realistico completo
    all_downloads = downloader.download_all_realistic_data()
    
    print(f"\nüéâ DOWNLOAD REALISTICO COMPLETATO!")
    print(f"üìÅ Controlla la directory '{downloader.base_dir}/' per i file")
    
    return all_downloads


if __name__ == "__main__":
    main()
